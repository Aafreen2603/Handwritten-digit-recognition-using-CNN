{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten-digit-recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+zkxFbu/7kG7a5re8rKbU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aafreen2603/Handwritten-digit-recognition-using-CNN/blob/main/Handwritten_digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten Digit Recognition \n",
        "### Deep Learning Project\n",
        "Libraries, Tools used:\n",
        "*   Python programming\n",
        "*   Deep learning (Convolutional Neural Networks) with Keras library \n",
        "*   Tensorflow and Keras libraries\n",
        "*   the Tkinter library for building GUI\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "To implement a **handwritten digit recognition app** which uses the image of a digit and recognizes the digit present in the image.\n",
        "\n",
        "This will be done using **Convolutional Neural Networks** which is a type of deep neural network.\n"
      ],
      "metadata": {
        "id": "6ZcF5NfHh7th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import the libraries and load the dataset into training and test data\n",
        "2. Preprocess the data\n",
        "3. Create the model\n",
        "4. Train the model using training data\n",
        "5. Evaluate the model using testing data\n"
      ],
      "metadata": {
        "id": "GGOreXmxpFvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset used: The MNIST dataset\n",
        "\n",
        "The MNIST dataset contains 60,000 training images of handwritten digits from zero to nine and 10,000 images for testing. So, the MNIST dataset has 10 different classes. The handwritten digits images are represented as a 28×28 matrix where each cell contains grayscale pixel value."
      ],
      "metadata": {
        "id": "CO8T-O0piREH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importing the libraries and loading dataset\n",
        "First, we are going to import all the modules that we are going to need for training our model. The Keras library already contains the MNIST dataset. So we can import the dataset and start working with it. \n",
        "\n",
        "The **mnist.load_data()** method returns us the training data, its labels and also the testing data and its labels.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sOuOHm9Iivb0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR1ROuIUhnMP"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vocrHvVyh7OU",
        "outputId": "029c6645-bbca-4a67-c904-5641aeda56d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preprocessing\n",
        "The image data cannot be fed directly into the model so we need to perform some operations and process the data to make it ready for our neural network. \n",
        "The dimension of the training data is (60000,28,28). \n",
        "The CNN model will require one more dimension so we reshape the matrix to shape (60000,28,28,1)."
      ],
      "metadata": {
        "id": "3B6WI6Y8jBrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)"
      ],
      "metadata": {
        "id": "M5E-aJEDjE2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes=None)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test,  num_classes=None)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Rhj4JcjN_H",
        "outputId": "c2dddb0a-4f0c-4fe4-bedf-178061b3d156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create the model\n",
        "A CNN model generally consists of convolutional and pooling layers. It works better for data that are represented as grid structures, this is the reason why CNN works well for image classification problems. The dropout layer is used to deactivate some of the neurons and while training, it reduces offer fitting of the model. \n",
        "We will then compile the model with the **Adadelta optimizer.**"
      ],
      "metadata": {
        "id": "Lu-gSTJkkj-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "#model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adadelta',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CdDL5EJ4jWmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train the model with training set\n",
        "The model.fit() function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size.\n",
        "\n",
        "It takes some time to train the model. After training, we save the weights and model definition in the ‘mnist.h5’ file."
      ],
      "metadata": {
        "id": "UMFeEC-4m1vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "print(\"The model has successfully trained\")\n",
        "\n",
        "model.save('mnist.h5')\n",
        "print(\"Saving the model as mnist.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfpky8KSk1fG",
        "outputId": "8a908575-df04-4847-d5cd-93a7c750b90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 171s 361ms/step - loss: 2.2670 - accuracy: 0.1616 - val_loss: 2.2040 - val_accuracy: 0.4045\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 163s 347ms/step - loss: 2.1648 - accuracy: 0.3230 - val_loss: 2.0785 - val_accuracy: 0.5917\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 162s 345ms/step - loss: 2.0332 - accuracy: 0.4525 - val_loss: 1.9103 - val_accuracy: 0.6761\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 160s 341ms/step - loss: 1.8559 - accuracy: 0.5514 - val_loss: 1.6883 - val_accuracy: 0.7297\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 160s 341ms/step - loss: 1.6417 - accuracy: 0.6136 - val_loss: 1.4299 - val_accuracy: 0.7727\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 158s 338ms/step - loss: 1.4170 - accuracy: 0.6579 - val_loss: 1.1792 - val_accuracy: 0.7975\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 160s 341ms/step - loss: 1.2153 - accuracy: 0.6873 - val_loss: 0.9755 - val_accuracy: 0.8151\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 161s 343ms/step - loss: 1.0638 - accuracy: 0.7096 - val_loss: 0.8271 - val_accuracy: 0.8292\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 159s 338ms/step - loss: 0.9478 - accuracy: 0.7332 - val_loss: 0.7213 - val_accuracy: 0.8396\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 159s 339ms/step - loss: 0.8676 - accuracy: 0.7470 - val_loss: 0.6460 - val_accuracy: 0.8479\n",
            "The model has successfully trained\n",
            "Saving the model as mnist.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that after each epoch, the accuracy increases and the loss decreases."
      ],
      "metadata": {
        "id": "aROqC7grrGtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Evaluation using the testing set\n",
        "\n",
        "We have 10,000 images in our testing dataset which will be used to evaluate how good our model works. \n"
      ],
      "metadata": {
        "id": "3fGxpZsRnDaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFxlivECm_ch",
        "outputId": "990bf5da-7df9-426b-b2f9-5d17dfc881a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6459946036338806\n",
            "Test accuracy: 0.8478999733924866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model has an accuracy of 84.79% on the test set. To increase this we can increase the number of epochs."
      ],
      "metadata": {
        "id": "KiFcnFedXdXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Woal33IOtv4R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}